sliderInput("g3_range", "Sélectionnez la plage pour la note G3",
min = 0, max = 20, value = c(0, 20)),
actionButton("plot_button", "Afficher les graphiques"),
HTML('<ul>
<li>Sélectionnez une ou plusieurs variables à partir du menu déroulant.</li>
<li>Sélectionnez la plage pour la note G3 à l&apos;aide du curseur.</li>
<li>Cliquez sur le bouton "Afficher les graphiques" pour générer les graphiques.</li>
</ul>'),
uiOutput("plots_ui")
)
)
),
skin = "black"
library(shiny)
library(shinydashboard)
library(readxl)
library(dplyr)
library(ggplot2)
library(plotly)
# Charger les données depuis un fichier Excel
data <- read_excel("student-mat.xlsx")
ui <- dashboardPage(
dashboardHeader(title = "Test"),
dashboardSidebar(
sidebarMenu(
menuItem("Introduction", tabName = "introduction", icon = icon("info-circle"))
)
),
dashboardBody(
tabItems(
tabItem(tabName = "introduction",
h2("Bienvenue dans l'application d'exploration des données !"),
p("Sélectionnez les variables que vous souhaitez explorer et cliquez sur 'Afficher les graphiques' pour voir les graphiques correspondants."),
br(),
h3("Instructions :"),
selectInput("variables", "Choisir des variables", multiple = TRUE, choices = colnames(data)),
sliderInput("g3_range", "Sélectionnez la plage pour la note G3",
min = 0, max = 20, value = c(0, 20)),
actionButton("plot_button", "Afficher les graphiques"),
HTML('<ul>
<li>Sélectionnez une ou plusieurs variables à partir du menu déroulant.</li>
<li>Sélectionnez la plage pour la note G3 à l&apos;aide du curseur.</li>
<li>Cliquez sur le bouton "Afficher les graphiques" pour générer les graphiques.</li>
</ul>'),
uiOutput("plots_ui")
)
)
),
skin = "black"
)
# Définir le dictionnaire des explications au niveau de l'environnement global
explanations <- list(
school = "student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira)",
# ... (les autres explications)
G3 = "final grade (numeric: from 0 to 20, output target)"
)
server <- function(input, output, session) {
observeEvent(input$plot_button, {
selected_variables <- input$variables
g3_range <- input$g3_range
filtered_data <- data %>%
filter(G3 >= g3_range[1] & G3 <= g3_range[2])
plots <- list()
for (variable in selected_variables) {
plot_data <- ggplot(filtered_data, aes(x = .data[[variable]])) +
geom_bar(fill = "turquoise") +
labs(x = variable, y = "Fréquence") +
ggtitle(explanations[[variable]]) +
theme(plot.title = element_text(hjust = 0.5, size = 10))
plotly_plot <- ggplotly(plot_data)
plots[[variable]] <- plotly_plot
}
output$plots_ui <- renderUI({
if (length(plots) == 0) {
return(NULL)
}
tagList(plots)
})
})
}
shinyApp(ui, server)
library(readxl)
library(dplyr)
library(caret)
data <- read_excel("student-mat.xlsx")
selected_vars <- c("age", "Medu", "Fedu", "traveltime", "studytime", "failures", "famrel", "freetime", "goout", "Dalc", "Walc", "health", "absences", "G1", "G2", "G3")
data <- data[selected_vars]
cor_matrix <- cor(data)
library(readxl)
library(dplyr)
library(caret)
data <- read_excel("student-mat.xlsx")
selected_vars <- c("age", "Medu", "Fedu", "traveltime", "studytime", "failures", "famrel", "freetime", "goout", "Dalc", "Walc", "health", "absences", "G1", "G2", "G3")
data <- data[selected_vars]
cor_matrix <- cor(data)
cor_matrix <- cor(data)
cor_matrix
library(heatmaply)
heatmaply(cor_matrix, symm = TRUE)
install.packages("heatmaply")
library(caret)
install.packages("caret")
library(readxl)
library(dplyr)
library(caret)
library(heatmaply)
install.packages("lattice")
library(readxl)
library(dplyr)
library(caret)
library(heatmaply)
data <- read_excel("student-mat.xlsx")
selected_vars <- c("age", "Medu", "Fedu", "traveltime", "studytime", "failures", "famrel", "freetime", "goout", "Dalc", "Walc", "health", "absences", "G1", "G2", "G3")
data <- data[selected_vars]
cor_matrix <- cor(data)
heatmaply(cor_matrix, symm = TRUE)
# Diviser les données en ensembles d'entraînement et de test
set.seed(123)  # Pour la reproductibilité
train_index <- createDataPartition(data$G3, p = 0.7, list = FALSE)
train_data <- data[train_index, ]
test_data <- data[-train_index, ]
# Entraîner un modèle de régression linéaire
model <- lm(G3 ~ ., data = train_data)
# Résumé du modèle
summary(model)
cor_matrix
library(randomForest)
set.seed(123)  # Pour la reproductibilité
train_index <- createDataPartition(data$G3, p = 0.7, list = FALSE)
train_data <- data[train_index, ]
test_data <- data[-train_index, ]
model_rf <- randomForest(G3 ~ ., data = train_data, ntree = 500)
predictions_rf <- predict(model_rf, newdata = test_data)
rmse_rf <- sqrt(mean((predictions_rf - test_data$G3)^2))
rsquared_rf <- 1 - (sum((predictions_rf - test_data$G3)^2) / sum((mean(test_data$G3) - test_data$G3)^2))
cat("RMSE (Random Forest):", rmse_rf, "\n")
cat("R-squared (Random Forest):", rsquared_rf, "
install.packages("randomForest")
install.packages("randomForest")
library(randomForest)
set.seed(123)  # Pour la reproductibilité
train_index <- createDataPartition(data$G3, p = 0.7, list = FALSE)
train_data <- data[train_index, ]
test_data <- data[-train_index, ]
model_rf <- randomForest(G3 ~ ., data = train_data, ntree = 500)
predictions_rf <- predict(model_rf, newdata = test_data)
rmse_rf <- sqrt(mean((predictions_rf - test_data$G3)^2))
rsquared_rf <- 1 - (sum((predictions_rf - test_data$G3)^2) / sum((mean(test_data$G3) - test_data$G3)^2))
cat("RMSE (Random Forest):", rmse_rf, "\n")
cat("R-squared (Random Forest):", rsquared_rf, "
library(randomForest)
set.seed(123)  # Pour la reproductibilité
train_index <- createDataPartition(data$G3, p = 0.7, list = FALSE)
train_data <- data[train_index, ]
test_data <- data[-train_index, ]
model_rf <- randomForest(G3 ~ ., data = train_data, ntree = 500)
predictions_rf <- predict(model_rf, newdata = test_data)
rmse_rf <- sqrt(mean((predictions_rf - test_data$G3)^2))
rsquared_rf <- 1 - (sum((predictions_rf - test_data$G3)^2) / sum((mean(test_data$G3) - test_data$G3)^2))
cat("RMSE (Random Forest):", rmse_rf, "\n")
cat("R-squared (Random Forest):", rsquared_rf, "\n")
set.seed(123)  # Pour la reproductibilité
train_index <- createDataPartition(data$G3, p = 0.7, list = FALSE)
train_data <- data[train_index, ]
test_data <- data[-train_index, ]
model_rf <- randomForest(G3 ~ ., data = train_data, ntree = 500)
predictions_rf <- predict(model_rf, newdata = test_data)
rmse_rf <- sqrt(mean((predictions_rf - test_data$G3)^2))
rsquared_rf <- 1 - (sum((predictions_rf - test_data$G3)^2) / sum((mean(test_data$G3) - test_data$G3)^2))
cat("RMSE (Random Forest):", rmse_rf, "\n")
cat("R-squared (Random Forest):", rsquared_rf, "\n")
variable_importance <- importance(model_rf)
print(variable_importance)
data <- read_excel("student-mat.xlsx")
selected_vars <- c(
"school", "sex", "age", "address", "famsize", "Pstatus", "Medu", "Fedu",
"Mjob", "Fjob", "reason", "guardian", "traveltime", "studytime", "failures",
"schoolsup", "famsup", "paid", "activities", "nursery", "higher", "internet",
"romantic", "famrel", "freetime", "goout", "Dalc", "Walc", "health",
"absences", "G1", "G2", "G3"
)
data <- data[selected_vars]
cor_matrix <- cor(data)
heatmaply(cor_matrix, symm = TRUE)
# se concentrer sur la premiere colonne
#### regression multiple ####
# Diviser les données en ensembles d'entraînement et de test
set.seed(123)  # Pour la reproductibilité
train_index <- createDataPartition(data$G3, p = 0.7, list = FALSE)
train_data <- data[train_index, ]
test_data <- data[-train_index, ]
# Entraîner un modèle de régression linéaire
model <- lm(G3 ~ ., data = train_data)
# Résumé du modèle
summary(model)
#### random forest ##"
library(randomForest)
set.seed(123)  # Pour la reproductibilité
train_index <- createDataPartition(data$G3, p = 0.7, list = FALSE)
train_data <- data[train_index, ]
test_data <- data[-train_index, ]
model_rf <- randomForest(G3 ~ ., data = train_data, ntree = 500)
predictions_rf <- predict(model_rf, newdata = test_data)
rmse_rf <- sqrt(mean((predictions_rf - test_data$G3)^2))
rsquared_rf <- 1 - (sum((predictions_rf - test_data$G3)^2) / sum((mean(test_data$G3) - test_data$G3)^2))
cat("RMSE (Random Forest):", rmse_rf, "\n")
cat("R-squared (Random Forest):", rsquared_rf, "\n")
variable_importance <- importance(model_rf)
print(variable_importance)
data <- data[selected_vars]
data
cor_matrix <- cor(data)
data <- read_excel("student-mat.xlsx")
selected_vars <- c(
"school", "sex", "age", "address", "famsize", "Pstatus", "Medu", "Fedu",
"Mjob", "Fjob", "reason", "guardian", "traveltime", "studytime", "failures",
"schoolsup", "famsup", "paid", "activities", "nursery", "higher", "internet",
"romantic", "famrel", "freetime", "goout", "Dalc", "Walc", "health",
"absences", "G1", "G2", "G3"
)
# Convertissez les variables catégorielles en numériques (si nécessaire)
data$school <- as.numeric(factor(data$school, levels = c("GP", "MS")))
data$sex <- as.numeric(factor(data$sex, levels = c("F", "M")))
data$address <- as.numeric(factor(data$address, levels = c("U", "R")))
data$famsize <- as.numeric(factor(data$famsize, levels = c("LE3", "GT3")))
data$Pstatus <- as.numeric(factor(data$Pstatus, levels = c("T", "A")))
data$Mjob <- as.numeric(factor(data$Mjob))
data$Fjob <- as.numeric(factor(data$Fjob))
data$reason <- as.numeric(factor(data$reason))
data$guardian <- as.numeric(factor(data$guardian))
data$schoolsup <- as.numeric(factor(data$schoolsup, levels = c("yes", "no")))
data$famsup <- as.numeric(factor(data$famsup, levels = c("yes", "no")))
data$paid <- as.numeric(factor(data$paid, levels = c("yes", "no")))
data$activities <- as.numeric(factor(data$activities, levels = c("yes", "no")))
data$nursery <- as.numeric(factor(data$nursery, levels = c("yes", "no")))
data$higher <- as.numeric(factor(data$higher, levels = c("yes", "no")))
data$internet <- as.numeric(factor(data$internet, levels = c("yes", "no")))
data$romantic <- as.numeric(factor(data$romantic, levels = c("yes", "no")))
# Calculez la matrice de corrélation
cor_matrix <- cor(data)
# Affichez la matrice de corrélation
print(cor_matrix)
heatmaply(cor_matrix, symm = TRUE)
view(data)
View(data)
# Diviser les données en ensembles d'entraînement et de test
set.seed(123)  # Pour la reproductibilité
train_index <- createDataPartition(data$G3, p = 0.7, list = FALSE)
train_data <- data[train_index, ]
test_data <- data[-train_index, ]
# Entraîner un modèle de régression linéaire
model <- lm(G3 ~ ., data = train_data)
# Résumé du modèle
summary(model)
# Diviser les données en ensembles d'entraînement et de test
set.seed(123)  # Pour la reproductibilité
train_index <- createDataPartition(data$G3, p = 0.7, list = FALSE)
train_data <- data[train_index, ]
test_data <- data[-train_index, ]
# Entraîner un modèle de régression linéaire
model <- lm(G3 ~ ., data = train_data)
# Résumé du modèle
summary(model)
library(randomForest)
set.seed(123)  # Pour la reproductibilité
train_index <- createDataPartition(data$G3, p = 0.7, list = FALSE)
train_data <- data[train_index, ]
test_data <- data[-train_index, ]
model_rf <- randomForest(G3 ~ ., data = train_data, ntree = 500)
predictions_rf <- predict(model_rf, newdata = test_data)
rmse_rf <- sqrt(mean((predictions_rf - test_data$G3)^2))
rsquared_rf <- 1 - (sum((predictions_rf - test_data$G3)^2) / sum((mean(test_data$G3) - test_data$G3)^2))
cat("RMSE (Random Forest):", rmse_rf, "\n")
cat("R-squared (Random Forest):", rsquared_rf, "\n")
variable_importance <- importance(model_rf)
print(variable_importance)
#1. Create training and test set .
set.seed (200)
n <- nrow ( student )
shuffled_stud <- student [ sample ( n ) , ]
train_indices <- 1: round (0.8 * n )
train <- shuffled_stud [ train_indices , ]
test_indices <- ( round (0.8 * n ) + 1): n
test <- shuffled_stud [ test_indices , ]
nrow ( train )
nrow ( test )
train $ pass <- ifelse ( train $ G3 >=10 ,1 ,0)
train $ pass <- as.factor ( train $ pass )
test $ pass <- ifelse ( test $ G3 >=10 ,1 ,0)
test $ pass <- as.factor ( test $ pass )
student $ pass <- ifelse ( student $ G3 >=10 ,1 ,0)
student $ pass <- as.factor ( student $ pass )
# Passing rates , entire ( Table 13)
mean ( student $ pass ==1)
# Passing rates , train / test ( Table 14)
mean ( train $ pass ==1)
mean ( test $ pass ==1)
# Tranformation of nominal variables to dummy variables
train $ reasonD <- as.factor ( ifelse ( train $ reason == " reputation " ," reputation " ,0))
train $ guardianD <- as.factor ( ifelse ( train $ guardian == " mother " ," mother " ,0))
train $ FjobD <- as.factor ( ifelse ( train $ Fjob == " teacher " ," teacher " ,0))
train $ MjobD <- as.factor ( ifelse ( train $ Mjob == " teacher " ," teacher " ,0))
test $ reasonD <- as.factor ( ifelse ( test $ reason == " home " ," home " ,0))
test $ guardianD <- as.factor ( ifelse ( test $ guardian == " mother " ," mother " ,0))
test $ FjobD <- as.factor ( ifelse ( test $ Fjob == " teacher " ," teacher " ,0))
test $ MjobD <- as.factor ( ifelse ( test $ Mjob == " teacher " ," teacher " ,0))
# Tranformation of age ( five levels , one category for age > 19)
train $ ageT <- NULL
train $ ageT <- train $ age
train $ ageT <- ifelse ( train $ ageT >=19 ,19 , train $ age )
train $ ageT <- as.factor ( train $ ageT )
levels ( train $ ageT ) <-c (1 ,2 ,3 ,4 ,5)
train $ ageT <- as.integer ( train $ ageT )
test $ ageT <- NULL
test $ ageT <- test $ age
test $ ageT <- ifelse ( test $ ageT >=19 ,19 , test $ age )
test $ ageT <- as.factor ( test $ ageT )
levels ( test $ ageT ) <-c (1 ,2 ,3 ,4 ,5)
test $ ageT <- as.integer ( test $ ageT )
# Select variables ( entire data set )
train_adjusted <- dplyr :: select ( train , - c ( G1 , G2 , G3 , reason , guardian , Fjob , Mjob , age ))
test_adjusted <- dplyr :: select ( test , - c ( G1 , G2 , G3 , reason , guardian , Fjob , Mjob , age ))
# Select variables ( reduced data set )
train_adjusted2 <- dplyr :: select ( train_adjusted , - c ( MjobD , FjobD , Walc , school , Dalc ))
test_adjusted2 <- dplyr :: select ( test_adjusted , - c ( MjobD , FjobD , Walc , school , Dalc ))
data<- read_excel("student-mat.xlsx")
set.seed (200)
n <- nrow ( data )
shuffled_stud <- data [ sample ( n ) , ]
train_indices <- 1: round (0.8 * n )
train <- shuffled_stud [ train_indices , ]
test_indices <- ( round (0.8 * n ) + 1): n
test <- shuffled_stud [ test_indices , ]
nrow ( train )
nrow ( test )
train $ pass <- ifelse ( train $ G3 >=10 ,1 ,0)
train $ pass <- as.factor ( train $ pass )
test $ pass <- ifelse ( test $ G3 >=10 ,1 ,0)
test $ pass <- as.factor ( test $ pass )
student $ pass <- ifelse ( student $ G3 >=10 ,1 ,0)
student $ pass <- as.factor ( student $ pass )
# Passing rates , entire ( Table 13)
mean ( student $ pass ==1)
# Passing rates , train / test ( Table 14)
mean ( train $ pass ==1)
mean ( test $ pass ==1)
# Tranformation of nominal variables to dummy variables
train $ reasonD <- as.factor ( ifelse ( train $ reason == " reputation " ," reputation " ,0))
train $ guardianD <- as.factor ( ifelse ( train $ guardian == " mother " ," mother " ,0))
train $ FjobD <- as.factor ( ifelse ( train $ Fjob == " teacher " ," teacher " ,0))
train $ MjobD <- as.factor ( ifelse ( train $ Mjob == " teacher " ," teacher " ,0))
test $ reasonD <- as.factor ( ifelse ( test $ reason == " home " ," home " ,0))
test $ guardianD <- as.factor ( ifelse ( test $ guardian == " mother " ," mother " ,0))
test $ FjobD <- as.factor ( ifelse ( test $ Fjob == " teacher " ," teacher " ,0))
test $ MjobD <- as.factor ( ifelse ( test $ Mjob == " teacher " ," teacher " ,0))
# Tranformation of age ( five levels , one category for age > 19)
train $ ageT <- NULL
train $ ageT <- train $ age
train $ ageT <- ifelse ( train $ ageT >=19 ,19 , train $ age )
train $ ageT <- as.factor ( train $ ageT )
levels ( train $ ageT ) <-c (1 ,2 ,3 ,4 ,5)
train $ ageT <- as.integer ( train $ ageT )
test $ ageT <- NULL
test $ ageT <- test $ age
test $ ageT <- ifelse ( test $ ageT >=19 ,19 , test $ age )
test $ ageT <- as.factor ( test $ ageT )
levels ( test $ ageT ) <-c (1 ,2 ,3 ,4 ,5)
test $ ageT <- as.integer ( test $ ageT )
# Select variables ( entire data set )
train_adjusted <- dplyr :: select ( train , - c ( G1 , G2 , G3 , reason , guardian , Fjob , Mjob , age ))
test_adjusted <- dplyr :: select ( test , - c ( G1 , G2 , G3 , reason , guardian , Fjob , Mjob , age ))
# Select variables ( reduced data set )
train_adjusted2 <- dplyr :: select ( train_adjusted , - c ( MjobD , FjobD , Walc , school , Dalc ))
test_adjusted2 <- dplyr :: select ( test_adjusted , - c ( MjobD , FjobD , Walc , school , Dalc ))
test_adjusted2
test
View(test)
library(randomForest)
set.seed(123)  # Pour la reproductibilité
train_index <- createDataPartition(data$G3, p = 0.7, list = FALSE)
train_data <- data[train_index, ]
test_data <- data[-train_index, ]
model_rf <- randomForest(G3 ~ ., data = train_data, ntree = 500)
predictions_rf <- predict(model_rf, newdata = test_data)
rmse_rf <- sqrt(mean((predictions_rf - test_data$G3)^2))
rsquared_rf <- 1 - (sum((predictions_rf - test_data$G3)^2) / sum((mean(test_data$G3) - test_data$G3)^2))
cat("RMSE (Random Forest):", rmse_rf, "\n")
cat("R-squared (Random Forest):", rsquared_rf, "\n")
variable_importance <- importance(model_rf)
print(variable_importance)
library ( vcd )
library ( vcdExtra )
# Select variables , Medu / Mjob :
MeduMjob <- dplyr :: select ( data , Medu , Mjob )
# Two - way table with observed proportion ( Table 6):
( Rowproptable <- round ( prop.table ( table ( MeduMjob ) , 1) ,2))
# Two - way table with observed and expected counts ( Table 5):
# The table was made manually in Latex using contTables below
library ( jmv )
contTables ( MeduMjob , rows = ' Medu ' , cols = ' Mjob ' , chiSq = TRUE , exp = TRUE , pcRow = TRUE )
# Pearson chi - squared test of independence and Pearson C
MMeduMjob = as.matrix ( TMeduMjob )
assocstats ( MMeduMjob )
# Select variables , studytime / traveltime :
studytimetraveltime <- dplyr :: select ( data , studytime , traveltime )
# CMH - test ( Table 8)
Mstudytimetraveltime = as.matrix ( table ( studytimetraveltime ))
CMHtest ( Mstudytimetraveltime )
# Correlation , Kendall ' s tau - b ( Table 9)
cor ( data $ traveltime , data $ studytime , method = " kendall " )
install.packages("vcd")
install.packages("vcdExtra")
install.packages("jmv")
library ( vcd )
library ( vcdExtra )
# Select variables , Medu / Mjob :
MeduMjob <- dplyr :: select ( data , Medu , Mjob )
# Two - way table with observed proportion ( Table 6):
( Rowproptable <- round ( prop.table ( table ( MeduMjob ) , 1) ,2))
# Two - way table with observed and expected counts ( Table 5):
# The table was made manually in Latex using contTables below
library ( jmv )
contTables ( MeduMjob , rows = ' Medu ' , cols = ' Mjob ' , chiSq = TRUE , exp = TRUE , pcRow = TRUE )
# Pearson chi - squared test of independence and Pearson C
MMeduMjob = as.matrix ( TMeduMjob )
assocstats ( MMeduMjob )
# Select variables , studytime / traveltime :
studytimetraveltime <- dplyr :: select ( data , studytime , traveltime )
# CMH - test ( Table 8)
Mstudytimetraveltime = as.matrix ( table ( studytimetraveltime ))
CMHtest ( Mstudytimetraveltime )
# Correlation , Kendall ' s tau - b ( Table 9)
cor ( data $ traveltime , data $ studytime , method = " kendall " )
data<- read_excel("student-mat.xlsx")
# --- --- --- --- --- --- --- --- -- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- -
library ( vcd )
library ( vcdExtra )
# Select variables , Medu / Mjob :
MeduMjob <- dplyr :: select ( data , Medu , Mjob )
# Two - way table with observed proportion ( Table 6):
( Rowproptable <- round ( prop.table ( table ( MeduMjob ) , 1) ,2))
# Two - way table with observed and expected counts ( Table 5):
# The table was made manually in Latex using contTables below
library ( jmv )
contTables ( MeduMjob , rows = ' Medu ' , cols = ' Mjob ' , chiSq = TRUE , exp = TRUE , pcRow = TRUE )
# Pearson chi - squared test of independence and Pearson C
MMeduMjob = as.matrix ( TMeduMjob )
model <- glm(G3 ~ school + sex + age + address + famsize + Pstatus + Medu + Fedu + Mjob + Fjob + reason + guardian +
traveltime + studytime + failures + schoolsup + famsup + paid + activities + nursery + higher +
internet + romantic + famrel + freetime + goout + Dalc + Walc + health + absences,
data = data, family = "binomial")
# Résumez le modèle
summary(model)
# Affichez les statistiques z et les p-valeurs pour chaque coefficient
coeff_summary <- summary(model)$coefficients
print(coeff_summary)
summary(model)
model <- glm(pass ~ school + sex + age + address + famsize + Pstatus + Medu + Fedu + Mjob + Fjob + reason + guardian +
traveltime + studytime + failures + schoolsup + famsup + paid + activities + nursery + higher +
internet + romantic + famrel + freetime + goout + Dalc + Walc + health + absences,
data = train, family = "binomial")
# Résumez le modèle
summary(model)
data$pass <-ifelse ( data $ G3 >=10 ,1 ,0)
data $ pass <- as.factor ( data$ pass )
# Créez un modèle de régression logistique (remplacez "data" par votre propre ensemble de données)
model <- glm(pass ~ school + sex + age + address + famsize + Pstatus + Medu + Fedu + Mjob + Fjob + reason + guardian +
traveltime + studytime + failures + schoolsup + famsup + paid + activities + nursery + higher +
internet + romantic + famrel + freetime + goout + Dalc + Walc + health + absences,
data = data, family = "binomial")
# Résumez le modèle
summary(model)
data<- read_excel("student-mat.xlsx")
data$pass <-ifelse ( data $ G3 >=10 ,1 ,0)
data $ pass <- as.factor ( data$ pass )
data1<-data
selected_vars <- c(
"school", "sex", "age", "address", "famsize", "Pstatus", "Medu", "Fedu",
"Mjob", "Fjob", "reason", "guardian", "traveltime", "studytime", "failures",
"schoolsup", "famsup", "paid", "activities", "nursery", "higher", "internet",
"romantic", "famrel", "freetime", "goout", "Dalc", "Walc", "health",
"absences", "G1", "G2", "G3","pass"
)
# Convertissez les variables catégorielles en numériques (si nécessaire)
data1$school <- as.numeric(factor(data$school, levels = c("GP", "MS")))
data1$sex <- as.numeric(factor(data$sex, levels = c("F", "M")))
data1$address <- as.numeric(factor(data$address, levels = c("U", "R")))
data1$famsize <- as.numeric(factor(data$famsize, levels = c("LE3", "GT3")))
data1$Pstatus <- as.numeric(factor(data$Pstatus, levels = c("T", "A")))
data1$Mjob <- as.numeric(factor(data$Mjob))
data1$Fjob <- as.numeric(factor(data$Fjob))
data1$reason <- as.numeric(factor(data$reason))
data1$guardian <- as.numeric(factor(data$guardian))
data1$schoolsup <- as.numeric(factor(data$schoolsup, levels = c("yes", "no")))
data1$famsup <- as.numeric(factor(data$famsup, levels = c("yes", "no")))
data1$paid <- as.numeric(factor(data$paid, levels = c("yes", "no")))
data1$activities <- as.numeric(factor(data$activities, levels = c("yes", "no")))
data1$nursery <- as.numeric(factor(data$nursery, levels = c("yes", "no")))
data1$higher <- as.numeric(factor(data$higher, levels = c("yes", "no")))
data1$internet <- as.numeric(factor(data$internet, levels = c("yes", "no")))
data1$romantic <- as.numeric(factor(data$romantic, levels = c("yes", "no")))
cor_matrix <- cor(data1)
print(cor_matrix)
heatmaply(cor_matrix, symm = TRUE)
View(data)
cor_matrix <- cor(data1$pass)
print(cor_matrix)
heatmaply(cor_matrix, symm = TRUE)
ncol(data1)
data1$pass<-as.numeric(factor(data$pass))
cor_matrix <- cor(data1)
heatmaply(cor_matrix, symm = TRUE)
